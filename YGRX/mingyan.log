2020-03-11 21:55:52 [twisted] CRITICAL: Unhandled error in Deferred:
2020-03-11 21:55:52 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/urllib/request.py", line 1318, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/http/client.py", line 1262, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/http/client.py", line 1308, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/http/client.py", line 1257, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/http/client.py", line 1036, in _send_output
    self.send(msg)
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/http/client.py", line 974, in send
    self.connect()
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/http/client.py", line 1415, in connect
    super().connect()
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/http/client.py", line 946, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/socket.py", line 724, in create_connection
    raise err
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/socket.py", line 713, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/urllib/request.py", line 223, in urlopen
    return opener.open(url, data, timeout)
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/urllib/request.py", line 1361, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/urllib/request.py", line 1320, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 111] Connection refused>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/site-packages/fake_useragent/utils.py", line 154, in load
    for item in get_browsers(verify_ssl=verify_ssl):
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/site-packages/fake_useragent/utils.py", line 97, in get_browsers
    html = get(settings.BROWSERS_STATS_PAGE, verify_ssl=verify_ssl)
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/site-packages/fake_useragent/utils.py", line 84, in get
    raise FakeUserAgentError('Maximum amount of retries reached')
fake_useragent.errors.FakeUserAgentError: Maximum amount of retries reached

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/site-packages/fake_useragent/utils.py", line 69, in get
    return response.read()
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/http/client.py", line 472, in read
    s = self._safe_read(self.length)
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/http/client.py", line 622, in _safe_read
    chunk = self.fp.read(min(amt, MAXAMOUNT))
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/socket.py", line 586, in readinto
    return self._sock.recv_into(b)
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/ssl.py", line 1012, in recv_into
    return self.read(nbytes, buffer)
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/ssl.py", line 874, in read
    return self._sslobj.read(len, buffer)
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/ssl.py", line 631, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/site-packages/twisted/internet/defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/site-packages/scrapy/crawler.py", line 86, in crawl
    self.engine = self._create_engine()
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/site-packages/scrapy/crawler.py", line 111, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/site-packages/scrapy/core/downloader/__init__.py", line 86, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/site-packages/scrapy/middleware.py", line 35, in from_settings
    mw = create_instance(mwcls, settings, crawler)
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/site-packages/scrapy/utils/misc.py", line 142, in create_instance
    return objcls.from_crawler(crawler, *args, **kwargs)
  File "/home/tlxy/桌面/项目练习/Scrapy_env/YGRX/YGRX/middlewares.py", line 123, in from_crawler
    return cls(crawler)
  File "/home/tlxy/桌面/项目练习/Scrapy_env/YGRX/YGRX/middlewares.py", line 116, in __init__
    self.ua = UserAgent()
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/site-packages/fake_useragent/fake.py", line 69, in __init__
    self.load()
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/site-packages/fake_useragent/fake.py", line 78, in load
    verify_ssl=self.verify_ssl,
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/site-packages/fake_useragent/utils.py", line 250, in load_cached
    update(path, use_cache_server=use_cache_server, verify_ssl=verify_ssl)
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/site-packages/fake_useragent/utils.py", line 245, in update
    write(path, load(use_cache_server=use_cache_server, verify_ssl=verify_ssl))
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/site-packages/fake_useragent/utils.py", line 189, in load
    verify_ssl=verify_ssl,
  File "/var/sw/anaconda3/envs/spider/lib/python3.6/site-packages/fake_useragent/utils.py", line 84, in get
    raise FakeUserAgentError('Maximum amount of retries reached')
fake_useragent.errors.FakeUserAgentError: Maximum amount of retries reached
